import torch
import re
from fastapi import FastAPI, HTTPException, Header
from pydantic import BaseModel
from typing import List, Optional
from transformers import pipeline
# from langdetect import detect, LangDetectException # –ú–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
API_KEY_SECRET = "python_secret_key"

class MultilingualSentimentAnalyzer:
    def __init__(self):
        print("INIT: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (CPU/GPU/MPS)...")
        if torch.backends.mps.is_available():
            self.device = torch.device("mps")
            print("‚úÖ INIT: –ò—Å–ø–æ–ª—å–∑—É—é Apple Silicon GPU (MPS)")
        elif torch.cuda.is_available():
            self.device = torch.device("cuda")
            print("‚úÖ INIT: –ò—Å–ø–æ–ª—å–∑—É—é NVIDIA GPU (CUDA)")
        else:
            self.device = torch.device("cpu")
            print("‚ö†Ô∏è INIT: –ò—Å–ø–æ–ª—å–∑—É—é CPU (–ú–µ–¥–ª–µ–Ω–Ω–æ)")

        model_name = "cardiffnlp/twitter-xlm-roberta-base-sentiment"

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        self.sentiment_pipeline = pipeline(
            "sentiment-analysis",
            model=model_name,
            tokenizer=model_name,
            device=self.device,
            top_k=None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ max
        )

        # –°–ø–∏—Å–æ–∫ –º–∞—Ç–æ–≤
        self.bad_words = {
            'ru': ['–¥—É—Ä–∞–∫', '–∏–¥–∏–æ—Ç', '—É—Ä–æ–¥', '—Ç—É–ø–æ–π', '–±–ª—è—Ç—å', '—Å—É–∫–∞', '—Ö–µ—Ä', '–º—É–¥–∞–∫'],
            'kk': ['–∞“õ—ã–º–∞“õ', '–µ—Å–µ–∫', '—Ç–æ–ø–∞—Å', '–∂—ã–Ω–¥—ã', '—â–µ—à–µ—Å', '–º–∞–ª'],
            'en': ['stupid', 'idiot', 'fuck', 'shit', 'bitch']
        }

        # –†—É—á–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
        self.manual_overrides = {
            "–ø–æ–ª–Ω–∞—è –µ—Ä—É–Ω–¥–∞": "negative",
            "–µ—Ä—É–Ω–¥–∞": "negative",
            "—á—É—à—å": "negative",
            "–±—Ä–µ–¥": "negative"
        }

    def detect_language(self, text):
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (–º–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å langdetect)
        kz_letters = set("”ô—ñ“£“ì“Ø“±“õ”©“ª”ò–Ü“¢“í“Æ“∞“ö”®“∫")
        if any(char in kz_letters for char in text):
            return 'kk'
        if re.search(r'[a-zA-Z]', text):
            return 'en'
        return 'ru' # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º RU, –µ—Å–ª–∏ –Ω–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

    def check_toxicity(self, text, lang):
        all_bad = self.bad_words.get(lang, self.bad_words['ru'] + self.bad_words['kk'])
        text_lower = text.lower()
        for word in all_bad:
            # –ò—â–µ–º —Å–ª–æ–≤–æ —Ü–µ–ª–∏–∫–æ–º, —á—Ç–æ–±—ã –Ω–µ –±–∞–Ω–∏—Ç—å "–æ—Å–∫–æ—Ä–±–ª—è—Ç—å" –∏–∑-–∑–∞ "–±–ª—è"
            if re.search(r'\b' + re.escape(word) + r'\b', text_lower):
                return True
        return False

    def analyze(self, comments: List[str]):
        results = [None] * len(comments)
        indices_to_process = []
        texts_to_process = []

        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ –º–µ—Ç–æ–∫
        # –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã, —É—á—Ç–µ–º –∏—Ö –≤—Å–µ
        label_map = {
            'LABEL_0': 'negative', '0': 'negative', 'negative': 'negative', 'Negative': 'negative',
            'LABEL_1': 'neutral',  '1': 'neutral',  'neutral': 'neutral',  'Neutral': 'neutral',
            'LABEL_2': 'positive', '2': 'positive', 'positive': 'positive', 'Positive': 'positive'
        }

        # 1. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ (—Ä—É—á–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞)
        for i, text in enumerate(comments):
            text_clean = text.lower().strip()
            lang = self.detect_language(text)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—É—Å—Ç–æ—Ç—É
            if not text_clean:
                results[i] = {"text": text, "sentiment": "neutral", "score": 0.0, "language": lang, "is_toxic": False}
                continue

            if text_clean in self.manual_overrides:
                results[i] = {
                    "text": text,
                    "sentiment": self.manual_overrides[text_clean],
                    "score": 1.0,
                    "language": lang,
                    "is_toxic": self.check_toxicity(text, lang)
                }
            else:
                indices_to_process.append(i)
                texts_to_process.append(text[:512])

        # 2. –ù–µ–π—Ä–æ—Å–µ—Ç—å
        if texts_to_process:
            batch_size = 16
            with torch.no_grad():
                for j in range(0, len(texts_to_process), batch_size):
                    batch_texts = texts_to_process[j : j + batch_size]
                    batch_indices = indices_to_process[j : j + batch_size]

                    try:
                        predictions = self.sentiment_pipeline(batch_texts)

                        for k, pred_list in enumerate(predictions):
                            # –ï—Å–ª–∏ pipeline –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ (–∏–Ω–æ–≥–¥–∞ –±—ã–≤–∞–µ—Ç), –±–µ—Ä–µ–º —Ç–æ–ø
                            if isinstance(pred_list, list):
                                top_pred = max(pred_list, key=lambda x: x['score'])
                            else:
                                top_pred = pred_list # –ò–Ω–æ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ä–∞–∑—É dict

                            raw_label = top_pred['label']

                            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –õ–æ–≥ –≤ –∫–æ–Ω—Å–æ–ª—å (—É–≤–∏–¥–∏—Ç–µ —ç—Ç–æ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ VS Code)
                            if j == 0 and k == 0:
                                print(f"üîç DEBUG: –ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –º–µ—Ç–∫—É: '{raw_label}'")

                            sentiment = label_map.get(raw_label, 'neutral') # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –±—É–¥–µ—Ç neutral

                            original_idx = batch_indices[k]
                            original_text = comments[original_idx]
                            lang = self.detect_language(original_text)

                            results[original_idx] = {
                                "text": original_text,
                                "sentiment": sentiment,
                                "score": round(top_pred['score'], 4),
                                "language": lang,
                                "is_toxic": self.check_toxicity(original_text, lang)
                            }

                        if self.device.type == 'mps':
                            torch.mps.empty_cache()

                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ: {e}")
                        # –ß—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç –Ω–µ –ø–∞–¥–∞–ª, –∑–∞–ø–æ–ª–Ω—è–µ–º –æ—à–∏–±–∫–∞–º–∏
                        for idx in batch_indices:
                             results[idx] = {
                                "text": comments[idx],
                                "sentiment": "neutral", # –§–æ–ª–±—ç–∫ –Ω–∞ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–∏ –æ—à–∏–±–∫–µ
                                "score": 0.0,
                                "language": "unknown",
                                "is_toxic": False
                            }

        return results
# --- API –°–ï–†–í–ï–† ---
app = FastAPI(title="AI Sentiment Service")
ai_engine = MultilingualSentimentAnalyzer()

class AnalysisRequest(BaseModel):
    comments: List[str]

@app.post("/analyze")
async def analyze_api(request: AnalysisRequest, x_api_key: str = Header(None)):
    if x_api_key != API_KEY_SECRET:
        raise HTTPException(status_code=403, detail="Invalid API Key")

    if not request.comments:
        return []

    return ai_engine.analyze(request.comments)

@app.get("/health")
async def health():
    return {"status": "ok", "device": str(ai_engine.device)}
